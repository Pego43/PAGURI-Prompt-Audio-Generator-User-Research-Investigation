{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77c4bbd9091bc922",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# P.A.G.U.R.I. : Prompt Audio Generator User Research Investigation\n",
    "Generate audio samples via text prompts and create your own custom music througout model fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a22f32ad-7f13-4624-b956-7b3453f95cc9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Insert User ID\n",
    "user_id = \"111111\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f2dcbd7-2829-4202-b06a-d10104b5fabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------USER ID-------------------------------------------------------\n",
      "\n",
      "USER ID : 111111\n",
      "\n",
      "\n",
      "----------------------------------------GPU AVAILABILITY---------------------------------------------------\n",
      "GPU Avaialbility : True\n",
      "Version : 11.7\n",
      "Number of GPU available: 3\n",
      "GPU 0: NVIDIA TITAN RTX\n",
      " -Total memory: 23.65 GB\n",
      " -Busy memory: 0.00 GB\n",
      " -Busy cache memory: 0.00 GB\n",
      " -Free memory: 23.65 GB\n",
      "GPU 1: NVIDIA TITAN RTX\n",
      " -Total memory: 23.65 GB\n",
      " -Busy memory: 0.00 GB\n",
      " -Busy cache memory: 0.00 GB\n",
      " -Free memory: 23.65 GB\n",
      "GPU 2: NVIDIA TITAN RTX\n",
      " -Total memory: 23.65 GB\n",
      " -Busy memory: 0.00 GB\n",
      " -Busy cache memory: 0.00 GB\n",
      " -Free memory: 23.65 GB\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "\n",
      "----------------------------------------INITIALIZATION---------------------------------------------------\n",
      "Already exist : /nas/home/gperego/projects/audiocraft/UserExperience/111111\n",
      "Created /nas/home/gperego/projects/audiocraft/UserExperience/111111/Generated_Sounds\n",
      "Already exist : /nas/home/gperego/projects/audiocraft/UserExperience/111111/Model\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Models  available: ['AudioLDM2 Model', 'My Model']\n",
      "Number of dataset available : ['BassSounds', 'Kalimba', 'GuitarRiff', 'LatinMusic', 'PersonalFlute', 'BigBandSwing', 'PunkRock', 'BassShot', 'FullDrum', 'DiscoBar', 'DrillBeat', 'PopBeat', 'Dreambow', 'Disco Music 80s', 'BigBandMusic', 'BassFin', 'LeadFin', 'PirateFolk', 'PirateMetal', 'TrashMetal', 'DrinkNow']\n",
      "---------------------------------------------READY---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#IMPORTS & SETTINGS\n",
    "#--------------------------------------------------------------------------------------------\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import io\n",
    "import scipy\n",
    "import torch\n",
    "import IPython\n",
    "import ipywidgets as widgets\n",
    "import random\n",
    "import os\n",
    "\n",
    "''' For setting particular GPUs devices'''\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3,4,5\"\n",
    "\n",
    "import datetime\n",
    "import pytz\n",
    "\n",
    "from ipywidgets import*\n",
    "from numba import cuda\n",
    "from diffusers import DPMSolverMultistepScheduler\n",
    "from dreambooth_audioldm2_notebook import train\n",
    "from pipeline.pipeline_audioldm import AudioLDMPipeline\n",
    "from pipeline.pipeline_audioldm2 import AudioLDM2Pipeline\n",
    "from IPython.display import Audio\n",
    "from IPython.display import display\n",
    "from IPython.display import Javascript\n",
    "\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.CRITICAL)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------\n",
    "#--------------------------------------------------------------------------------------\n",
    "#-------------------------------GLOBAL VARIABLES---------------------------------------\n",
    "#--------------------------------------------------------------------------------------\n",
    "path_experiments = \"/nas/home/gperego/projects/audiocraft/UserExperience\"\n",
    "model_audioldm2 = \"cvssp/audioldm2\"\n",
    "SAMPLE_RATE = 16000\n",
    "#--------------------------------------------------------------------------------------\n",
    "#----------------------------------FUNCTIONS-------------------------------------------\n",
    "#--------------------------------------------------------------------------------------\n",
    "# GPU AVAILABILITY\n",
    "def gpu_availability_function():\n",
    "    print(f\"GPU Avaialbility : {torch.cuda.is_available()}\\n\"\n",
    "          f\"Version : {torch.version.cuda}\")\n",
    "    #CUDA(GPU) availability\n",
    "    if torch.cuda.is_available():\n",
    "        # Number of GPUs available\n",
    "        num_devices = torch.cuda.device_count()\n",
    "        print(f\"Number of GPU available: {num_devices}\")\n",
    "        # GPU info\n",
    "        for i in range(num_devices):\n",
    "            gpu_device = torch.cuda.get_device_properties(i)\n",
    "            print(f\"GPU {i}: {gpu_device.name}\\n -Total memory: {gpu_device.total_memory / (1024 ** 3):.2f} GB\")\n",
    "            allocated_memory = torch.cuda.memory_allocated(i)\n",
    "            print(f\" -Busy memory: {allocated_memory / 1024**3:.2f} GB\")\n",
    "            cached_memory = torch.cuda.memory_reserved(i)\n",
    "            print(f\" -Busy cache memory: {cached_memory / 1024**3:.2f} GB\")\n",
    "            free_memory = gpu_device.total_memory - allocated_memory - cached_memory\n",
    "            print(f\" -Free memory: {free_memory / 1024**3:.2f} GB\")\n",
    "    else:\n",
    "        print(\"CUDA is not available. Make sure you have a GPU and PyTorch configured correctly.\")\n",
    "        \n",
    "def restartkernel() :\n",
    "    IPython.Application.instance().kernel.do_shutdown(True)\n",
    "    \n",
    "def norm_audio(audio):\n",
    "    # Find the abs maximum value of the signal\n",
    "    max_val = np.max(np.abs(audio))\n",
    "    # Normalization of the signal between -1 and 1\n",
    "    normAudio = audio / max_val if max_val != 0 else audio\n",
    "    return normAudio\n",
    "    \n",
    "def folder_creation(path,folder):\n",
    "    global user_id\n",
    "    full_path = os.path.join(path,folder)\n",
    "    if not os.path.exists(full_path):\n",
    "        os.makedirs(full_path)\n",
    "        print(f\"Created {full_path}\")\n",
    "    else:\n",
    "        print(f\"Already exist : {full_path}\")\n",
    "    if folder==user_id:\n",
    "            current_time = datetime.datetime.now(pytz.timezone('Europe/Rome'))\n",
    "            with open(full_path+f\"/user_{user_id}_data.txt\", 'a') as file:\n",
    "                file.write(\"-------------------------------------------------------------------\"+'\\n'+user_id+'_'+str(current_time)+'\\n')\n",
    "    return full_path\n",
    "\n",
    "def path_exist(input_path):\n",
    "    if os.path.exists(input_path):\n",
    "        return input_path\n",
    "    else:\n",
    "        return None\n",
    "        \n",
    "def change_data(path_data,w,id):\n",
    "    with open(path_data, 'r') as file:\n",
    "        first_line = file.readline()\n",
    "        first_line = first_line.strip()\n",
    "        words = first_line.split('_')\n",
    "        new_word = w\n",
    "        words[id] = new_word\n",
    "    with open(path_data, 'w') as file:\n",
    "        new_line = '_'.join(words)\n",
    "        file.write(new_line)\n",
    "\n",
    "def folder_string_counter(directory, string):\n",
    "    count = 0\n",
    "    for entry in os.listdir(directory):\n",
    "        full_path = os.path.join(directory, entry)\n",
    "        if os.path.isdir(full_path):\n",
    "            if string in entry:\n",
    "                count += 1\n",
    "    return count\n",
    "\n",
    "def folder_file_counter(directory):\n",
    "    k=0\n",
    "    if path_exist(directory) is not None:\n",
    "        for file_name in os.listdir(directory):\n",
    "            k=k+1\n",
    "        return k\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def model_available_setup(model_path):\n",
    "    m = []\n",
    "    if path_exist(model_path+\"/trained_pipeline\") is None:\n",
    "        m = ['AudioLDM2 Model']\n",
    "    else:\n",
    "        m = ['AudioLDM2 Model','My Model']\n",
    "    return m\n",
    "\n",
    "def folder_available_setup(directory):\n",
    "    f = []\n",
    "    n = []\n",
    "    if path_exist(directory) is not None:\n",
    "        for file_name in os.listdir(directory):\n",
    "            #print(file_name)\n",
    "            f.append(os.path.join(directory, file_name))\n",
    "            n.append(file_name)\n",
    "        return f,n\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def file_show(directory):\n",
    "    n = []\n",
    "    if path_exist(directory) is not None:\n",
    "        for file_name in os.listdir(directory):\n",
    "            #print(file_name)\n",
    "            n.append(file_name)\n",
    "        return n\n",
    "    else:\n",
    "        return None\n",
    "#------------------------------------------------------------------------------------------------------------------\n",
    "#------------------------------------------------INITIALIZATION----------------------------------------------------\n",
    "#------------------------------------------------------------------------------------------------------------------\n",
    "print(\"\\n--------------------------------------------USER ID-------------------------------------------------------\")\n",
    "print(f\"\\nUSER ID : {user_id}\\n\")\n",
    "print(\"\\n----------------------------------------GPU AVAILABILITY---------------------------------------------------\")\n",
    "gpu_availability_function()\n",
    "CUDA_LAUNCH_BLOCKING=1\n",
    "print(\"-----------------------------------------------------------------------------------------------------------\")\n",
    "print(\"\\n----------------------------------------INITIALIZATION---------------------------------------------------\")\n",
    "user_path = folder_creation(path_experiments,user_id)\n",
    "user_txt_path = user_path+f\"/user_{user_id}_data.txt\"\n",
    "sounds_id_path = folder_creation(user_path,\"Generated_Sounds\")\n",
    "model_path = folder_creation(user_path,\"Model\")\n",
    "models = model_available_setup(model_path)\n",
    "sounds_id = folder_file_counter(sounds_id_path)\n",
    "data = folder_string_counter(user_path,\"Training_Data\")\n",
    "train_status = 0\n",
    "generation_number = 0\n",
    "print(\"---------------------------------------------------------------------------------------------------------\")\n",
    "print(f\"Models  available: {models}\")\n",
    "foldersData, folderNames = folder_available_setup(\"/nas/home/gperego/projects/audiocraft/UserExperience/UserDatasets\")\n",
    "print(f\"Number of dataset available : {folderNames}\")\n",
    "print(\"---------------------------------------------READY---------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3640fcf123cf4c2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-05T14:24:01.864006100Z",
     "start_time": "2024-02-05T14:24:01.769043200Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# GENERATION\n",
    "#FUNCTIONS\n",
    "\n",
    "def load_sound(input_string):\n",
    "    model_id = model_audioldm2\n",
    "    if len(input_string)>=2:\n",
    "        #Loading Model\n",
    "        if (model_available.value == \"My Model\" and path_exist(user_path+\"/Model/trained_pipeline\") ):\n",
    "            model_id = path_exist(user_path+\"/Model/trained_pipeline\")\n",
    "        else:\n",
    "            model_id = model_audioldm2\n",
    "        pipe = AudioLDM2Pipeline.from_pretrained(model_id, torch_dtype=torch.float16).to(\"cuda\")\n",
    "        #Generation of sound\n",
    "        w = pipe(input_string,num_inference_steps=200,num_waveforms_per_prompt=num_waves.value,audio_length_in_s=audio_lenght.value).audios\n",
    "        #Normalization of sound\n",
    "        for i,x in enumerate(w):\n",
    "            w[i] = norm_audio(x)   \n",
    "        return w\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def clear_text(b):\n",
    "    text.value = ''\n",
    "    \n",
    "def clear_output(b):\n",
    "    output_generation.clear_output()\n",
    "    \n",
    "def on_button_generation(b):\n",
    "    global sounds_id_path, user_id, sounds_id\n",
    "    output_generation.clear_output()\n",
    "    with output_generation:\n",
    "        rate = SAMPLE_RATE\n",
    "        audios = load_sound(text.value)\n",
    "        if audios is not None:\n",
    "            output_generation.clear_output()\n",
    "            #Name_modelName_numberOfWaveformsGenerated_lenghtInSeconds\n",
    "            \n",
    "            with open(user_path+f\"/user_{user_id}_data.txt\", 'a') as file:\n",
    "                    file.write(f\"GENERATION\\n\")\n",
    "\n",
    "            for i,x in enumerate(audios):\n",
    "                if (sounds_id < 10):\n",
    "                    name = f\"G0{sounds_id}-{i+1}-{text.value}\"\n",
    "                else:\n",
    "                    name = f\"G{sounds_id}-{i+1}-{text.value}\"\n",
    "                    \n",
    "                print(name)\n",
    "                audio_widget = Audio(data=x,rate=rate)\n",
    "\n",
    "                with open(user_txt_path, 'a') as file:\n",
    "                    #Name_modelName_numberOfWaveformsGenerated_lenghtInSeconds\n",
    "                    file.write(f\"{name}_{model_available.value}_{num_waves.value}_{audio_lenght.value}\\n\")\n",
    "\n",
    "                    \n",
    "                scipy.io.wavfile.write(sounds_id_path+\"/\"+name+\".wav\",rate=rate,data=x)\n",
    "                display(audio_widget)\n",
    "                sounds_id = sounds_id+1\n",
    "        else:\n",
    "            print(\"Prompt not valid!!!\")\n",
    "    \n",
    "# GUI OBJECTS           \n",
    "output_generation = widgets.Output(layout={'border': '2px solid white'})   \n",
    "output_evaluation = widgets.Output(layout={'border': '2px solid white'}) \n",
    "\n",
    "text = widgets.Textarea(value='',placeholder='...',description='',disabled=False,rows=2,layout={'width': '500px'})\n",
    "clear_text_button = widgets.Button(description=\"Delete text\")\n",
    "clear_output_button = widgets.Button(description=\"Clear output\")\n",
    "empty_button = widgets.Button(description=\"\", disabled=True)\n",
    "\n",
    "generate_sound_button = widgets.Button(description=\"Generate\",layout={'border': '2px solid green'})\n",
    "model_available = Dropdown(options=models, description='')\n",
    "num_waves = widgets.IntSlider(description=' ', min=1, max=5, step=1, value=3)\n",
    "audio_lenght = widgets.IntSlider(description=' ', min=2.0, max=10.0, step=1.0, value=5.0)\n",
    "\n",
    "horizontal_text_box = widgets.HBox([text,generate_sound_button,clear_output_button])\n",
    "horizontal_generation_box = widgets.HBox([model_available,num_waves,audio_lenght])\n",
    "\n",
    "\n",
    "# EVENTS   \n",
    "clear_text_button.on_click(clear_text)\n",
    "clear_output_button.on_click(clear_output)\n",
    "generate_sound_button.on_click(on_button_generation)\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed42cbcd962de6be",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# FINE-TUNING\n",
    "#FUNCTIONS\n",
    "check_file_button = 0\n",
    "\n",
    "def f(x):\n",
    "    return x\n",
    "\n",
    "def f_1_elements(a):\n",
    "    print((a))\n",
    "\n",
    "def f_2_elements(a, b):\n",
    "    print((a, b)) \n",
    "    \n",
    "def f_3_elements(a, b, c):\n",
    "    print((a, b, c)) \n",
    "\n",
    "def f_4_elements(a,b,c,d):\n",
    "    print((a,b,c,d))\n",
    "\n",
    "def f_5_elements(a,b,c,d,e):\n",
    "    print((a,b,c,d,f\"Dataset: {e}\"))\n",
    "\n",
    "\n",
    "def handle_upload(b):\n",
    "    global check_file_button\n",
    "    output_upload.clear_output()\n",
    "    check_file_button = check_file_button + 1\n",
    "    check_file_button = check_file_button % 2\n",
    "    if check_file_button == 1:\n",
    "        button_upload.description=\"Hide files\"\n",
    "        #button_upload.layout={'border': '2px solid red'}\n",
    "        a = []\n",
    "        l = []\n",
    "        dataset_index = folderNames.index(folders_available.value)\n",
    "        DATA_DIR0 = foldersData[dataset_index]\n",
    "\n",
    "        for i,file_name in enumerate(os.listdir(DATA_DIR0)):\n",
    "            print(f'{i + 1}: {file_name}')\n",
    "            audio_data, _ = librosa.load(DATA_DIR0+\"/\"+file_name, sr=SAMPLE_RATE)\n",
    "            audio_data = norm_audio(audio_data)\n",
    "            a.append(audio_data)\n",
    "            l.append(file_name)\n",
    "        with output_upload:\n",
    "            if len(a)==0:\n",
    "                print(\"No files selected...\")\n",
    "                return\n",
    "            print(\"------------------------------------------\")\n",
    "            for i,x in enumerate(a):\n",
    "                print(f\"0{i+1}-{l[i]}\")\n",
    "                display(Audio(x, rate=SAMPLE_RATE))\n",
    "    else:\n",
    "        output_upload.clear_output()\n",
    "        button_upload.description=\"Listen files\"\n",
    "       \n",
    "def strat_train_on_click(b):\n",
    "    global data , train_status\n",
    "    \n",
    "    audios = []\n",
    "    labels = []\n",
    "    dataset_index = folderNames.index(folders_available.value)\n",
    "    DATA_DIR0 = foldersData[dataset_index]\n",
    "\n",
    "    for i,file_name in enumerate(os.listdir(DATA_DIR0)):\n",
    "        print(f'{i + 1}: {file_name}')\n",
    "        audio_data, _ = librosa.load(DATA_DIR0+\"/\"+file_name, sr=SAMPLE_RATE)\n",
    "        audio_data = norm_audio(audio_data)\n",
    "        audios.append(audio_data)\n",
    "        labels.append(file_name)\n",
    "    \n",
    "    if (len(audios)>=1 and len(audios)<=5) and (len(instance.value)>=3) and (len(object_class.value)>=3):\n",
    "\n",
    "        train_status = train_status + 1\n",
    "        \n",
    "        #Folder creation\n",
    "        DATA_DIR = folder_creation(user_path,f\"Training_Data_{data}\")\n",
    "        dataset_index = folderNames.index(folders_available.value)\n",
    "        DATA_DIR0 = foldersData[dataset_index]\n",
    "        data = data+1\n",
    "\n",
    "        #Save Audios\n",
    "        for i,a in enumerate(audios):\n",
    "            w = norm_audio(a)\n",
    "            scipy.io.wavfile.write(DATA_DIR + f\"/{i+1}-{labels[i]}.wav\", rate=SAMPLE_RATE, data=w)\n",
    "        #Define model to train\n",
    "        if model_name.value == \"My Model\":\n",
    "            MODEL_NAME = model_path+\"/trained_pipeline\"\n",
    "        else:\n",
    "            MODEL_NAME = \"cvssp/audioldm2\"\n",
    "        #Define output folder\n",
    "        OUTPUT_DIR = model_path\n",
    "        #Define train parameters\n",
    "        INSTANCE_WORD = instance.value\n",
    "        OBJECT_CLASS = object_class.value\n",
    "        LEARNING_RATE = 4.0 * 10.0 ** (-5)\n",
    "        if training_type.value=='Fast':\n",
    "            TRAIN_STEPS = 100\n",
    "        elif training_type.value == 'Medium':\n",
    "            TRAIN_STEPS = 200\n",
    "        elif training_type.value == 'Slow':\n",
    "            TRAIN_STEPS = 500\n",
    "        else:\n",
    "            TRAIN_STEPS = 5\n",
    "            LEARNING_RATE = 2.0 * 10.0 ** (-2)\n",
    "            \n",
    "        with output_training:\n",
    "            output_training.clear_output()\n",
    "            print(f\"START TRAINING\")\n",
    "            print(dataset_index)\n",
    "            print(DATA_DIR0)\n",
    "            \n",
    "            train(True,MODELNAME=MODEL_NAME,DATAPATH=DATA_DIR,OUTPATH=OUTPUT_DIR,\n",
    "              INSTANCEWORD=INSTANCE_WORD,OBJECTCLASS=OBJECT_CLASS,TRAINSTEPS=TRAIN_STEPS,\n",
    "              NUMVECTORS=4,LEARNINGRATE=LEARNING_RATE,TRAINBATCHSIZE=1,GRADIENTACCUMULATION=2)\n",
    "                \n",
    "            print(f\"----------------------------------------------------------------------------------------------\")\n",
    "            output_training.clear_output()\n",
    "            print(f\"CHECK...\")\n",
    "            p = path_exist(user_path+\"/Model/trained_pipeline\")\n",
    "            if (p != None) and (\"My Model\" not in model_name.options):\n",
    "                model_name.options = list(model_name.options) + [\"My Model\"]\n",
    "                model_available.options = list(model_available.options) + [\"My Model\"]\n",
    "            button_train.disabled=False\n",
    "            output_training.clear_output()\n",
    "\n",
    "            with open(user_path+f\"/user_{user_id}_data.txt\", 'a') as file:\n",
    "                    file.write(f\"Training_{INSTANCE_WORD}_{OBJECT_CLASS}_{model_name.value}_{training_type.value}_{len(audios)}-audios\\n\")\n",
    "                \n",
    "            print(f\"END TRAINING : train status = {train_status}\")\n",
    "            if train_status==2:\n",
    "                print(\"For train again the model, please restart the kernel: Run -> Restart Kernel and Run All Cells... -> Restart \")\n",
    "                button_train.disabled=True\n",
    "            else:\n",
    "                print(\"'My Model' is available\")\n",
    "                \n",
    "    else:\n",
    "        with output_training:\n",
    "            output_training.clear_output()\n",
    "            print(f\"ERROR : input parameters not corrected = {train_status}\")\n",
    "\n",
    "def uploaded_files(change):\n",
    "    global check_file_button\n",
    "    output_upload.clear_output()\n",
    "    output_training.clear_output()\n",
    "    with output_upload:\n",
    "        output_upload.clear_output()\n",
    "        button_upload.disabled = False\n",
    "        button_upload.description=\"Show files\"\n",
    "        button_upload.layout={'border': '2px solid green'}\n",
    "        check_file_button = 0\n",
    "        button_train.disabled = False\n",
    "        button_train.description=\"Start Fine-Tuning\"\n",
    "        file_dict = upload_widget.value\n",
    "        num_file = len(file_dict)\n",
    "        print(f\"Number of files: {num_file}\")\n",
    "        if num_file > 0:\n",
    "            print(\"--------------------------------------------------------------------------------\")\n",
    "            for i,x in enumerate(upload_widget.value):\n",
    "                print(f\"{i+1}-{x['name']}\")\n",
    "                  \n",
    "#OBJECTS    \n",
    "\n",
    "upload_widget = widgets.FileUpload(accept='.wav, .mp3',multiple=True)\n",
    "\n",
    "output_upload = widgets.Output(layout={'border': '0px solid black'}) \n",
    "output_training = widgets.Output(layout={'border': '2px solid white'}) \n",
    "\n",
    "button_upload = widgets.Button(description=\"Listen files\",disabled=False)\n",
    "button_space = widgets.Button(description='', disabled=True)\n",
    "button_train = widgets.Button(description=\"Start\",disabled=False,layout={'border': '2px solid lightblue'})\n",
    "\n",
    "instance = widgets.Text(value='',placeholder='...',description='',disabled=False)\n",
    "object_class = widgets.Text(value='',placeholder='...',description='',disabled=False)\n",
    "model_name = Dropdown(options=models, description='')\n",
    "training_type = Dropdown(options=['Fast','Medium','Slow'], description='')\n",
    "folders_available = Dropdown(options=folderNames, description='')\n",
    "\n",
    "train_prompt_setup_out = widgets.interactive_output(f_5_elements, {'a': instance, 'b': object_class, 'c': model_name, \n",
    "                                                                   'd': training_type, 'e' : folders_available})\n",
    "\n",
    "horizontal_box_prompt = widgets.HBox([instance, object_class, model_name,training_type])\n",
    "horizontal_box_train_values = widgets.HBox([train_prompt_setup_out])\n",
    "horizontal_box_upload = widgets.HBox([button_train,button_space,folders_available,button_upload])\n",
    "\n",
    "# EVENTS   \n",
    "button_upload.on_click(handle_upload)\n",
    "button_train.on_click(strat_train_on_click)\n",
    "upload_widget.observe(uploaded_files, names='value')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fddb61-bff0-4cec-a195-0654c292a6ab",
   "metadata": {},
   "source": [
    "# P.A.G.U.R.I. - User GUIDE\n",
    "_______________________________________________________________________________________________________________________ \n",
    "- **GENERATE YOUR AUDIOS FROM TEXT**\n",
    "  - Insert your text into *INPUT PROMPT* text-box.\n",
    "  - Select the model generator from *MODELS AVAILABLE* list.\n",
    "  - Select the number of waveform to generate using the *NUMBER OF WAVES PER PROMPT* slider.\n",
    "  - Select the duration of audios using the *AUDIO DURATION IN SECONDS* slider.\n",
    "  - Click on \"GENERATE\" button to generate music from your input prompt text.\n",
    "  - Click on *CLEAR OUTPUT* button to clear the audio files generated window.\n",
    "_______________________________________________________________________________________________________________________    \n",
    "- **TRAIN YOUR MODEL WITH YOUR OWN AUDIOS**\n",
    "  - Insert an Instance Word (at LEAST three characters) in *INSTANCE WORD* text-box, for satisfy the model association between text prompt and output music.\n",
    "  - Insert an Object Class (at LEAST three characters) in *OBJECT CLASS* text-box, for satisfy the model association between text prompt and output music.\n",
    "  - Select the model generator you want to fine-tune from * MODELS AVAILABLE* list.\n",
    "  - Select the kind of training procedure from *FINE-TUNING TIME* list (Fast,Medium,Slow).\n",
    "  - Select the dataset of music to personalize by choosing one from those available in \"SOUND DATASET AVAILABLE\" list.\n",
    "  - Click on *LISTEN FILES* button to see and listen to your audio samples from the music dataset selected.\n",
    "  - Click on *HIDE FILES* button to visualize the names of your audio samples from the music dataset selected.\n",
    "  - Click on *START* button to start the fine-tuning of the model with your personal audio samples data.\n",
    "_______________________________________________________________________________________________________________________ \n",
    "- **SUGGESTIONS FOR A CORRECT USE**\n",
    "  - Perform one step at a time: don’t be hasty\n",
    "  - Fine-tuning accepts only 3 ~ 5 files, no more and no less\n",
    "  - Fine-tuning time : Fast : 5 - 7 min ; Medium : 10 - 13 min ; Slow : 18 - 20 min\n",
    "  - Choose a not common word as INSTANCE WORD for the fine-tuning of the model.\n",
    "  - To properly use the personalized model you created: select \"My Model\" from *MODELS AVAILABLE* list and insert in the *INPUT PROMPT* text-box\n",
    "    a sentence that includes INSTANCE WORD and OBJECT CLASS used for fine-tuning the model\n",
    "\n",
    "    Prompt example: *\" a sound of sks electric guitar\"* , where : INSTANCE WORD = \"sks\" and OBJECT CLASS = \"electric guitar\"\n",
    "_______________________________________________________________________________________________________________________ \n",
    "- **CREDITS**\n",
    "  \n",
    "  This code is heavily based on : *Investigating Personalization Methods in Text to Music Generation Generation*\n",
    "  \n",
    "  Paper reference : (https://arxiv.org/abs/2309.11140)\n",
    "  \n",
    "  Github reference : (https://github.com/zelaki/DreamSound)\n",
    "\n",
    "  \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02545397-dbe7-4824-b1bc-fc7308da4cae",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fb38ee4b404414b8af7cf76f99c775a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='GENERATE YOUR MUSIC FROM TEXT', layout=Layout(border_bottom='2px solid grey', border_left='2px so…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT PROMPT                                                             GENERATE SOUND       CLEAR OUTPUT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5520ab796fc444d591cd28e9c762e115",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Textarea(value='', layout=Layout(width='500px'), placeholder='...', rows=2), Button(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MODELS AVAILABLE                                       NUMBER OF AUDIO PER PROMPT                AUDIO DURATION IN SECONDS\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9fde7975e1f44dbb8b8fcebf4f44670",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Dropdown(options=('AudioLDM2 Model', 'My Model'), value='AudioLDM2 Model'), IntSlider(value=3, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf33c133013c4fec8347533058127040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border_bottom='2px solid white', border_left='2px solid white', border_right='2px solid w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4076adea9762494fb4da098cdd593d76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='CREATE A PERSONALIZED MODEL WITH YOUR AUDIO', layout=Layout(border_bottom='2px solid lightblue', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSTANCE WORD                         OBJECT CLASS                           MODELS AVAILABLE                      FINE-TUNING TIME\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4539212b9f446eabdaea275889e087c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Text(value='', placeholder='...'), Text(value='', placeholder='...'), Dropdown(options=('AudioL…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "627a8109fdf84fd4b23c600c02ba7864",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATE YOUR MODEL                         SOUND DATASET AVAIABLE                     LISTEN-HIDE AUDIO FILES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b56f795693204f71abdf89b9aa494f3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='Start', layout=Layout(border_bottom='2px solid lightblue', border_left='2px…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd8a4ded02574b56a035503026a50b9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border_bottom='0px solid black', border_left='0px solid black', border_right='0px solid b…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57343668486547a7ae2a12d296e1fafb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border_bottom='2px solid white', border_left='2px solid white', border_right='2px solid w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# P.A.G.U.R.I DISPLAY\n",
    "description_generate = f\"GENERATE YOUR MUSIC FROM TEXT\"\n",
    "generation_descriptor = widgets.Label(value=description_generate,layout={'border': '2px solid grey'})\n",
    "display(generation_descriptor)\n",
    "print(\"INPUT PROMPT                                                             GENERATE SOUND       CLEAR OUTPUT\")\n",
    "display(horizontal_text_box)\n",
    "print(\"\\nMODELS AVAILABLE                                       NUMBER OF AUDIO PER PROMPT                AUDIO DURATION IN SECONDS\")\n",
    "display(horizontal_generation_box)\n",
    "display(output_generation)\n",
    "\n",
    "# DISPLAY\n",
    "description_train = f\"CREATE A PERSONALIZED MODEL WITH YOUR AUDIO\"\n",
    "generation_train = widgets.Label(value=description_train,layout={'border': '2px solid lightblue'})\n",
    "display(generation_train)\n",
    "print(\"INSTANCE WORD                         OBJECT CLASS                           MODELS AVAILABLE                      FINE-TUNING TIME\")\n",
    "display(horizontal_box_prompt)\n",
    "display(horizontal_box_train_values)\n",
    "print(\"\\nCREATE YOUR MODEL                         SOUND DATASET AVAIABLE                     LISTEN-HIDE AUDIO FILES\")\n",
    "display(horizontal_box_upload)\n",
    "display(output_upload)\n",
    "display(output_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b894bed-f86d-4d98-89bf-3d75f7cd8c8c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc277f7-56aa-424e-b9e1-2b40c0f8c67d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
